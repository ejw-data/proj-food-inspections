{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12e7725c-2c7a-439e-9f43-bdee30b7132f",
   "metadata": {},
   "source": [
    "## Food Inspection: Creating a Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06a1f5d",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to create a better preprocessing pipeline method by utilizing the ColumnTransformer method.  I have used pipelines in the past but most of those steps were for balancing the data, standardizing data, running different models, and optimizing the models.  Most of the preprocessing apsects in those cases had already been done manually by using pandas.  In this notebook, I aim to include in my pipeline processes for manipulating columns based on data type, interpolating missing data, and potentially creating custom transformers to handle special cases.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f70d422-5779-4b15-a969-701681bbde3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "matplotlib          3.7.1\n",
       "numpy               1.23.5\n",
       "pandas              1.5.3\n",
       "seaborn             0.12.2\n",
       "session_info        1.0.0\n",
       "sklearn             1.2.2\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "PIL                         9.4.0\n",
       "asttokens                   NA\n",
       "backcall                    0.2.0\n",
       "beta_ufunc                  NA\n",
       "binom_ufunc                 NA\n",
       "bottleneck                  1.3.5\n",
       "cffi                        1.15.1\n",
       "cloudpickle                 2.2.1\n",
       "colorama                    0.4.6\n",
       "comm                        0.1.2\n",
       "cycler                      0.10.0\n",
       "cython_runtime              NA\n",
       "dateutil                    2.8.2\n",
       "debugpy                     1.5.1\n",
       "decorator                   5.1.1\n",
       "defusedxml                  0.7.1\n",
       "entrypoints                 0.4\n",
       "executing                   0.8.3\n",
       "google                      NA\n",
       "hypergeom_ufunc             NA\n",
       "invgauss_ufunc              NA\n",
       "ipykernel                   6.19.2\n",
       "ipython_genutils            0.2.0\n",
       "ipywidgets                  8.0.4\n",
       "jedi                        0.18.1\n",
       "joblib                      1.1.1\n",
       "jupyter_server              1.23.4\n",
       "kiwisolver                  1.4.4\n",
       "mkl                         2.4.0\n",
       "mpl_toolkits                NA\n",
       "nbinom_ufunc                NA\n",
       "ncf_ufunc                   NA\n",
       "nct_ufunc                   NA\n",
       "ncx2_ufunc                  NA\n",
       "nt                          NA\n",
       "ntsecuritycon               NA\n",
       "numexpr                     2.8.4\n",
       "packaging                   23.0\n",
       "parso                       0.8.3\n",
       "patsy                       0.5.3\n",
       "pickleshare                 0.7.5\n",
       "pkg_resources               NA\n",
       "platformdirs                2.5.2\n",
       "prompt_toolkit              3.0.36\n",
       "psutil                      5.9.0\n",
       "pure_eval                   0.2.2\n",
       "pyarrow                     11.0.0\n",
       "pydev_ipython               NA\n",
       "pydevconsole                NA\n",
       "pydevd                      2.6.0\n",
       "pydevd_concurrency_analyser NA\n",
       "pydevd_file_utils           NA\n",
       "pydevd_plugins              NA\n",
       "pydevd_tracing              NA\n",
       "pygments                    2.15.1\n",
       "pyparsing                   3.0.9\n",
       "pythoncom                   NA\n",
       "pytz                        2022.7\n",
       "pywintypes                  NA\n",
       "scipy                       1.10.1\n",
       "setuptools                  68.0.0\n",
       "six                         1.16.0\n",
       "skewnorm_ufunc              NA\n",
       "sphinxcontrib               NA\n",
       "stack_data                  0.2.0\n",
       "statsmodels                 0.14.0\n",
       "threadpoolctl               2.2.0\n",
       "tornado                     6.2\n",
       "traitlets                   5.7.1\n",
       "typing_extensions           NA\n",
       "wcwidth                     0.2.5\n",
       "win32api                    NA\n",
       "win32com                    NA\n",
       "win32security               NA\n",
       "zmq                         23.2.0\n",
       "zoneinfo                    NA\n",
       "zope                        NA\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             8.12.0\n",
       "jupyter_client      7.4.9\n",
       "jupyter_core        5.3.0\n",
       "jupyterlab          3.5.3\n",
       "notebook            6.5.4\n",
       "-----\n",
       "Python 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]\n",
       "Windows-10-10.0.22000-SP0\n",
       "-----\n",
       "Session information updated at 2023-09-07 14:54\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "\n",
    "# # Code formatter\n",
    "# # !pip3 install nb_black\n",
    "# %load_ext nb_black\n",
    "\n",
    "# eda tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualization dependencies\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns  \n",
    "\n",
    "# machine learning libraries\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestClassifier  \n",
    "\n",
    "# pipeline generation\n",
    "from sklearn.pipeline import Pipeline  \n",
    "from sklearn.compose import ColumnTransformer  \n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# hide jupyter lab warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# expand the number of dataframe columns visible\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "# make sound when this code executes: Audio(sound_file, autoplay=True)\n",
    "from IPython.display import Audio\n",
    "sound_file = './sound/chord.wav'\n",
    "\n",
    "# display package informatin\n",
    "# !conda install -c conda-forge session-info\n",
    "import session_info\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd8d6b-ae54-431a-b3e5-096177db2910",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49b59f72-38f4-409b-a44c-230f4b34ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "restaurant_df = pd.read_csv('./data/manipulated/combined_data.csv', parse_dates=['inspect_date', 'approx_start_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9927c029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renamed first column - caused by including the index during the export from `feature_extraction.ipynb`.  This is the original index.  \n",
    "restaurant_df.rename(columns={'Unnamed: 0':'original_index'}, inplace=True)\n",
    "\n",
    "# simplify column headers (after one-hot-encoding these categories become header titles)\n",
    "temp_dict = {'Risk 1 (High)':'high', 'Risk 2 (Medium)':'medium', 'Risk 3 (Low)':'low',np.nan: np.nan}\n",
    "restaurant_df['risk'] = restaurant_df['risk'].apply(lambda x: temp_dict[x])\n",
    "\n",
    "# limit dataset records\n",
    "df = restaurant_df[restaurant_df['inspect_date'] > '2018-01-01'] \n",
    "\n",
    "# define target and feature columns\n",
    "# maybe add violation id number to the model\n",
    "target = df['results']\n",
    "\n",
    "columns = ['risk', 'inspect_type', 'violation_count',\n",
    "       'vl_must_comply_count',\n",
    "       'vl_instructed_comply_count',\n",
    "       'vl_citation_count', 'ward', \n",
    "       'license_code', 'bus_activity_id',\n",
    "       'application_type', 'conditional_approval',\n",
    "       'bus_age', 'number_of_chains']\n",
    "features = df[columns]\n",
    "\n",
    "# Convert objects to category\n",
    "features[features.select_dtypes(['object']).columns] = features.select_dtypes(['object']).apply(lambda x: x.astype('category'))\n",
    "\n",
    "# Convert non-objects to category\n",
    "features['ward'] = features['ward'].astype('category')\n",
    "features['license_code'] = features['license_code'].astype('category')\n",
    "\n",
    "# Convert float to integer\n",
    "features['bus_age'] = features['bus_age'].astype('int')\n",
    "\n",
    "# create labels for model\n",
    "# I would like to add this to the pipeline but scikit-learn does not have this builtin for classfication\n",
    "# The regression version of this TransformedTargetRegressor\n",
    "# The closest extension is mlinsights and their TransformedTargetClassifier2\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(target)\n",
    "encoded_target = label_encoder.transform(target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84decfc",
   "metadata": {},
   "source": [
    "### Pipeline method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88e199cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=40, min_samples_leaf=5, n_jobs=-1,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=40, min_samples_leaf=5, n_jobs=-1,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=40, min_samples_leaf=5, n_jobs=-1,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# # load model\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    clf_rf = pickle.load(f)\n",
    "\n",
    "# view model\n",
    "clf_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a488c056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model - split data, select model, fit model and output accuracy as generic outcome\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, encoded_target, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3af4db",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/columntransformer-for-numerical-and-categorical-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad8992eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify numeric and categorial columns\n",
    "numeric_features = make_column_selector(dtype_exclude='category')\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    # ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "categorical_features = make_column_selector(dtype_include='category')\n",
    "categorical_transformer = OneHotEncoder(categories='auto', handle_unknown='ignore') \n",
    "\n",
    "\n",
    "# add number and category transformations and specify columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "119dba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "clf_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', clf_rf)\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47894060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6400029987255417\n"
     ]
    }
   ],
   "source": [
    "# train pipeline on data\n",
    "clf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# show score - need to evaluation with classification report  \n",
    "print(clf_pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e68102d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['fit_time', 'score_time', 'test_accuracy', 'train_accuracy', 'test_precision', 'train_precision', 'test_recall', 'train_recall', 'test_neg_mean_absolute_error', 'train_neg_mean_absolute_error'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "score_methods = ['accuracy', 'precision', 'recall', 'neg_mean_absolute_error']\n",
    "scores = cross_validate(clf_pipeline, X_train, y_train, scoring=score_methods, cv=cv, n_jobs=-1, return_train_score=True)\n",
    "\n",
    "\n",
    "\n",
    "# scores = np.absolute(scores[3])\n",
    "# print('MAE: %.3f (%.3f)' % (np.mean(scores[3]), np.std(scores[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32e17ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['fit_time', 'score_time', 'test_accuracy', 'train_accuracy', 'test_precision', 'train_precision', 'test_recall', 'train_recall', 'test_neg_mean_absolute_error', 'train_neg_mean_absolute_error'])\n",
      "0.6461490699289196 0.00868774646190784\n",
      "0.6765604270618965 0.0023670199280752314\n"
     ]
    }
   ],
   "source": [
    "print(scores.keys())\n",
    "print(scores['test_accuracy'].mean(), scores['test_accuracy'].std())\n",
    "print(scores['train_accuracy'].mean(), scores['train_accuracy'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17ad4d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Varname</th>\n",
       "      <th>Imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>violation_count</td>\n",
       "      <td>0.467353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vl_citation_count</td>\n",
       "      <td>0.272344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>inspect_type_Canvass Re-Inspection</td>\n",
       "      <td>0.023362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bus_age</td>\n",
       "      <td>0.023032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>inspect_type_Canvass</td>\n",
       "      <td>0.018197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>inspect_type_Complaint</td>\n",
       "      <td>0.017604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>number_of_chains</td>\n",
       "      <td>0.016485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>inspect_type_Complaint Re-Inspection</td>\n",
       "      <td>0.011700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>inspect_type_License</td>\n",
       "      <td>0.008287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ward_42.0</td>\n",
       "      <td>0.006746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>inspect_type_License Re-Inspection</td>\n",
       "      <td>0.005819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vl_instructed_comply_count</td>\n",
       "      <td>0.004820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vl_must_comply_count</td>\n",
       "      <td>0.004306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>risk_high</td>\n",
       "      <td>0.004230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>bus_activity_id_775</td>\n",
       "      <td>0.004135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>bus_activity_id_735</td>\n",
       "      <td>0.003933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>application_type_ISSUE</td>\n",
       "      <td>0.003510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>risk_medium</td>\n",
       "      <td>0.003415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>application_type_RENEW</td>\n",
       "      <td>0.003340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>license_code_1006.0</td>\n",
       "      <td>0.003134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>bus_activity_id_781</td>\n",
       "      <td>0.003102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>ward_41.0</td>\n",
       "      <td>0.002915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ward_13.0</td>\n",
       "      <td>0.002909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ward_34.0</td>\n",
       "      <td>0.002728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>inspect_type_Short Form Complaint</td>\n",
       "      <td>0.002672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ward_27.0</td>\n",
       "      <td>0.002402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>license_code_1475.0</td>\n",
       "      <td>0.002399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>ward_44.0</td>\n",
       "      <td>0.002290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ward_1.0</td>\n",
       "      <td>0.002283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>bus_activity_id_782</td>\n",
       "      <td>0.002193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ward_2.0</td>\n",
       "      <td>0.001978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>ward_47.0</td>\n",
       "      <td>0.001945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>ward_48.0</td>\n",
       "      <td>0.001870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ward_11.0</td>\n",
       "      <td>0.001808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ward_4.0</td>\n",
       "      <td>0.001798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ward_18.0</td>\n",
       "      <td>0.001775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>ward_43.0</td>\n",
       "      <td>0.001705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>ward_35.0</td>\n",
       "      <td>0.001653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ward_32.0</td>\n",
       "      <td>0.001625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ward_25.0</td>\n",
       "      <td>0.001612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>ward_50.0</td>\n",
       "      <td>0.001577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>ward_33.0</td>\n",
       "      <td>0.001567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>ward_39.0</td>\n",
       "      <td>0.001465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>bus_activity_id_638</td>\n",
       "      <td>0.001450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>inspect_type_Recent Inspection</td>\n",
       "      <td>0.001449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ward_28.0</td>\n",
       "      <td>0.001446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ward_6.0</td>\n",
       "      <td>0.001443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>ward_46.0</td>\n",
       "      <td>0.001421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>conditional_approval_N</td>\n",
       "      <td>0.001405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ward_5.0</td>\n",
       "      <td>0.001389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Varname       Imp\n",
       "0                         violation_count  0.467353\n",
       "3                       vl_citation_count  0.272344\n",
       "10     inspect_type_Canvass Re-Inspection  0.023362\n",
       "4                                 bus_age  0.023032\n",
       "9                    inspect_type_Canvass  0.018197\n",
       "11                 inspect_type_Complaint  0.017604\n",
       "5                        number_of_chains  0.016485\n",
       "12   inspect_type_Complaint Re-Inspection  0.011700\n",
       "14                   inspect_type_License  0.008287\n",
       "62                              ward_42.0  0.006746\n",
       "15     inspect_type_License Re-Inspection  0.005819\n",
       "2              vl_instructed_comply_count  0.004820\n",
       "1                    vl_must_comply_count  0.004306\n",
       "6                               risk_high  0.004230\n",
       "231                   bus_activity_id_775  0.004135\n",
       "151                   bus_activity_id_735  0.003933\n",
       "269                application_type_ISSUE  0.003510\n",
       "8                             risk_medium  0.003415\n",
       "270                application_type_RENEW  0.003340\n",
       "71                    license_code_1006.0  0.003134\n",
       "237                   bus_activity_id_781  0.003102\n",
       "61                              ward_41.0  0.002915\n",
       "33                              ward_13.0  0.002909\n",
       "54                              ward_34.0  0.002728\n",
       "18      inspect_type_Short Form Complaint  0.002672\n",
       "47                              ward_27.0  0.002402\n",
       "80                    license_code_1475.0  0.002399\n",
       "64                              ward_44.0  0.002290\n",
       "21                               ward_1.0  0.002283\n",
       "248                   bus_activity_id_782  0.002193\n",
       "22                               ward_2.0  0.001978\n",
       "67                              ward_47.0  0.001945\n",
       "68                              ward_48.0  0.001870\n",
       "31                              ward_11.0  0.001808\n",
       "24                               ward_4.0  0.001798\n",
       "38                              ward_18.0  0.001775\n",
       "63                              ward_43.0  0.001705\n",
       "55                              ward_35.0  0.001653\n",
       "52                              ward_32.0  0.001625\n",
       "45                              ward_25.0  0.001612\n",
       "70                              ward_50.0  0.001577\n",
       "53                              ward_33.0  0.001567\n",
       "59                              ward_39.0  0.001465\n",
       "114                   bus_activity_id_638  0.001450\n",
       "17         inspect_type_Recent Inspection  0.001449\n",
       "48                              ward_28.0  0.001446\n",
       "26                               ward_6.0  0.001443\n",
       "66                              ward_46.0  0.001421\n",
       "271                conditional_approval_N  0.001405\n",
       "25                               ward_5.0  0.001389"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_columns = list(clf_pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out())\n",
    "numerical_columns = features.columns[features.dtypes != 'category'].tolist()\n",
    "cols = numerical_columns + onehot_columns\n",
    "\n",
    "# show dataframe of feature name and model importance\n",
    "imp_df = pd.DataFrame({\n",
    "    \"Varname\": cols,\n",
    "    \"Imp\": clf_pipeline.steps[1][1].feature_importances_\n",
    "})\n",
    "temp = imp_df.sort_values(by=\"Imp\", ascending=False)\n",
    "temp.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a20242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save model  \n",
    "with open('model2.pkl','wb') as f:\n",
    "    pickle.dump(clf,f)\n",
    "\n",
    "# # load model\n",
    "# with open('model.pkl', 'rb') as f:\n",
    "#     clf2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9c96814",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'high'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m classification_report\n\u001b[0;32m      7\u001b[0m \u001b[39m# Get the predictions and labels\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m predictions \u001b[39m=\u001b[39m clf_pipeline\u001b[39m.\u001b[39;49msteps[\u001b[39m1\u001b[39;49m][\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mpredict(X_train)\n\u001b[0;32m      9\u001b[0m labels \u001b[39m=\u001b[39m y_train\n\u001b[0;32m     11\u001b[0m \u001b[39m# Get the classification report\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ejwda\\Anaconda3\\envs\\python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:820\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    800\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 820\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[0;32m    822\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    823\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ejwda\\Anaconda3\\envs\\python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:862\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    860\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    861\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[1;32m--> 862\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[0;32m    864\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    865\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mc:\\Users\\ejwda\\Anaconda3\\envs\\python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 602\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    603\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[0;32m    604\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ejwda\\Anaconda3\\envs\\python310\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\ejwda\\Anaconda3\\envs\\python310\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ejwda\\Anaconda3\\envs\\python310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ejwda\\Anaconda3\\envs\\python310\\lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'high'"
     ]
    }
   ],
   "source": [
    "# show evaluation of training data  \n",
    "# note1:  this evaluation is not very useful except when comparing the differences to the test data set\n",
    "# note2:  large changes in the model fit (going down between the train and test) indicate that there is overfitting occuring.  \n",
    "# note3:  underfitting is observed by seeing large errors in the model.  \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get the predictions and labels\n",
    "predictions = clf_pipeline.steps[1][1].predict(X_train)\n",
    "labels = y_train\n",
    "\n",
    "# Get the classification report\n",
    "report = classification_report(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65f2047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evaluation of testing data  \n",
    "# Get the predictions and labels\n",
    "predictions = clf.predict(X_test)\n",
    "labels = y_test\n",
    "\n",
    "# Get the classification report\n",
    "report = classification_report(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a22c7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ROC/AUC evaluation  \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "# Predict the labels of the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plot_roc_curve(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd61d95",
   "metadata": {},
   "source": [
    "### Analysis  \n",
    "- compare classification report\n",
    "- evaluate feature importance  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6860d2a7",
   "metadata": {},
   "source": [
    "### Future Steps  \n",
    "- What features to remove\n",
    "- What features to add to the model  \n",
    "- Change CV eval metric from accuracy to precision/recall\n",
    "- Create new notebook for further evaluation - classification reports, ROC/AUC curves  \n",
    "- Maybe add food type (geo_feature notebook) and menu information to model  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12e7725c-2c7a-439e-9f43-bdee30b7132f",
   "metadata": {},
   "source": [
    "## Food Inspection Feature Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dabf044-c72b-47b2-a019-2c8bb408cee2",
   "metadata": {},
   "source": [
    "### Potential Features  \n",
    "\n",
    "1.  name  \n",
    "1.  license number  \n",
    "1.  result (pass/fail)\n",
    "1.  business age (default start from 2010 inspection date)  \n",
    "1.  *number of chains / is_chain boolean \n",
    "1.  risk  \n",
    "1.  ward / neighborhood\n",
    "1.  license code  \n",
    "1.  renew  \n",
    "1.  conditional approved  \n",
    "1.  business activity\n",
    "1.  *number of (pass/fail) inspections during 1st, 2nd, 3rd, and 4th most recent  license period\n",
    "    * this can have errors so maybe use years from year_min to simplify\n",
    "1.  *geoapify number of starbucks within 0.5 mile radius  \n",
    "1.  *geoapify related business within 0.5 mile radius  \n",
    "1.  *us census track info of income  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f803ee-2d36-474c-830c-8b0a66aeca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Code formatter\n",
    "# # !pip3 install nb_black\n",
    "# %load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f70d422-5779-4b15-a969-701681bbde3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "# eda tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "import re\n",
    "\n",
    "# hide jupyter lab warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# expand the number of dataframe columns visible\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "# make sound when this code executes: Audio(sound_file, autoplay=True)\n",
    "from IPython.display import Audio\n",
    "sound_file = './sound/chord.wav'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db7170a4-fc21-47ad-92c1-c5b8ef144f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "matplotlib          3.7.1\n",
       "numpy               1.23.5\n",
       "pandas              1.5.3\n",
       "session_info        1.0.0\n",
       "sklearn             1.2.2\n",
       "statsmodels         0.14.0\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "PIL                         9.4.0\n",
       "asttokens                   NA\n",
       "backcall                    0.2.0\n",
       "beta_ufunc                  NA\n",
       "binom_ufunc                 NA\n",
       "bottleneck                  1.3.5\n",
       "cffi                        1.15.1\n",
       "cloudpickle                 2.2.1\n",
       "colorama                    0.4.6\n",
       "comm                        0.1.2\n",
       "cycler                      0.10.0\n",
       "cython_runtime              NA\n",
       "dateutil                    2.8.2\n",
       "debugpy                     1.5.1\n",
       "decorator                   5.1.1\n",
       "defusedxml                  0.7.1\n",
       "entrypoints                 0.4\n",
       "executing                   0.8.3\n",
       "google                      NA\n",
       "hypergeom_ufunc             NA\n",
       "invgauss_ufunc              NA\n",
       "ipykernel                   6.19.2\n",
       "ipython_genutils            0.2.0\n",
       "jedi                        0.18.1\n",
       "joblib                      1.1.1\n",
       "jupyter_server              1.23.4\n",
       "kiwisolver                  1.4.4\n",
       "mkl                         2.4.0\n",
       "mpl_toolkits                NA\n",
       "nbinom_ufunc                NA\n",
       "ncf_ufunc                   NA\n",
       "nct_ufunc                   NA\n",
       "ncx2_ufunc                  NA\n",
       "nt                          NA\n",
       "ntsecuritycon               NA\n",
       "numexpr                     2.8.4\n",
       "packaging                   23.0\n",
       "parso                       0.8.3\n",
       "patsy                       0.5.3\n",
       "pickleshare                 0.7.5\n",
       "pkg_resources               NA\n",
       "platformdirs                2.5.2\n",
       "prompt_toolkit              3.0.36\n",
       "psutil                      5.9.0\n",
       "pure_eval                   0.2.2\n",
       "pyarrow                     11.0.0\n",
       "pydev_ipython               NA\n",
       "pydevconsole                NA\n",
       "pydevd                      2.6.0\n",
       "pydevd_concurrency_analyser NA\n",
       "pydevd_file_utils           NA\n",
       "pydevd_plugins              NA\n",
       "pydevd_tracing              NA\n",
       "pygments                    2.15.1\n",
       "pyparsing                   3.0.9\n",
       "pytz                        2022.7\n",
       "scipy                       1.10.1\n",
       "setuptools                  68.0.0\n",
       "six                         1.16.0\n",
       "skewnorm_ufunc              NA\n",
       "sphinxcontrib               NA\n",
       "stack_data                  0.2.0\n",
       "threadpoolctl               2.2.0\n",
       "tornado                     6.2\n",
       "traitlets                   5.7.1\n",
       "typing_extensions           NA\n",
       "wcwidth                     0.2.5\n",
       "win32api                    NA\n",
       "win32security               NA\n",
       "zmq                         23.2.0\n",
       "zoneinfo                    NA\n",
       "zope                        NA\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             8.12.0\n",
       "jupyter_client      7.4.9\n",
       "jupyter_core        5.3.0\n",
       "jupyterlab          3.5.3\n",
       "notebook            6.5.4\n",
       "-----\n",
       "Python 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]\n",
       "Windows-10-10.0.22000-SP0\n",
       "-----\n",
       "Session information updated at 2023-08-25 10:32\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display package informatin\n",
    "# !conda install -c conda-forge session-info\n",
    "import session_info\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6407ad6-91e6-4ecb-ba41-414f6e203157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_select(row):\n",
    "    if str(row.license_start_date) != 'NaT': \n",
    "        temp = row.license_start_date\n",
    "    elif str(row.license_issued_date) != 'NaT':\n",
    "        temp = row.license_issued_date\n",
    "    elif str(row.app_complete) != 'NaT':\n",
    "        temp = row.app_complete\n",
    "    elif str(row.date_issued) != 'NaT':\n",
    "        temp = row.date_issued\n",
    "    elif str(row.license_end_date) != 'NaT':\n",
    "        temp = row.license_end_date\n",
    "    else:\n",
    "        temp = np.datetime64('nat')\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd8d6b-ae54-431a-b3e5-096177db2910",
   "metadata": {},
   "source": [
    "## Clean Food Safety Inspection Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b59f72-38f4-409b-a44c-230f4b34ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "inspections_df = pd.read_csv('data/original/food_inspections.csv', parse_dates=['Inspection Date'])\n",
    "print(f'Original number of records: {len(inspections_df)}')\n",
    "inspections_df.dropna(subset='License #', inplace=True)\n",
    "inspections_df['License #'].astype('int32')\n",
    "\n",
    "restaurant_df = inspections_df[inspections_df['Facility Type'] == 'Restaurant'].copy()\n",
    "restaurant_df = restaurant_df[~(restaurant_df['License #'] == 0)]\n",
    "restaurant_df.drop(['DBA Name', 'Location'], axis=1, inplace=True)\n",
    "restaurant_df = restaurant_df[~restaurant_df['Results'].isin(['Out of Business','No Entry', 'Not Ready', 'Business Not Located'])]\n",
    "restaurant_df.columns = ['inspect_id', 'aka_name', 'license_num', 'facility_type', 'risk',\n",
    "                           'address', 'city', 'state', 'zipcode', 'inspect_date', 'inspect_type',\n",
    "                           'results', 'violations', 'lat', 'lon']\n",
    "\n",
    "# strip white space from object types\n",
    "columns = restaurant_df.select_dtypes(['object']).columns\n",
    "restaurant_df[columns] = restaurant_df[columns].apply(lambda x: x.str.strip())\n",
    "\n",
    "# restaurant_df.dropna(subset=['violations'], inplace=True)\n",
    "restaurant_df['violations'].fillna('-99.  No violations reported', inplace=True)\n",
    "restaurant_df['violations_list'] = restaurant_df['violations'].apply(lambda x: x.split(\"|\"))\n",
    "restaurant_df['violation_count'] = restaurant_df['violations_list'].apply(lambda x: len(x))\n",
    "\n",
    "restaurant_df['violation_number'] = restaurant_df['violations_list'].apply(lambda x: [re.findall(r'\\b\\d+\\b',i)[0] for i in x])\n",
    "restaurant_df.head(3)\n",
    "\n",
    "restaurant_df['vl_must_comply_list'] = restaurant_df['violations_list'].apply(lambda x: [ 'MUST COMPLY' in i for i in x])\n",
    "restaurant_df['vl_must_comply_count'] = restaurant_df['vl_must_comply_list'].apply(lambda x: sum(x))\n",
    "\n",
    "restaurant_df['vl_instructed_comply_list'] = restaurant_df['violations_list'].apply(lambda x: ['INSTRUCTED TO COMPLY' in i for i in x])\n",
    "restaurant_df['vl_instructed_comply_count'] = restaurant_df['vl_instructed_comply_list'].apply(lambda x: sum(x))\n",
    "\n",
    "restaurant_df['vl_not_cited_list'] = restaurant_df['violations_list'].apply(lambda x: ['NO CITATION ISSUED' in i for i in x])\n",
    "restaurant_df['vl_citation_count'] = restaurant_df['vl_not_cited_list'].apply(lambda x: len(x) - sum(x))  \n",
    "\n",
    "restaurant_df['year'] = restaurant_df['inspect_date'].dt.strftime('%Y').astype('int')\n",
    "restaurant_df['month'] = restaurant_df['inspect_date'].dt.strftime('%m').astype('int')\n",
    "\n",
    "restaurant_df.drop_duplicates(subset=['aka_name','license_num','facility_type','risk','address','city','state',\n",
    "                                     'zipcode','inspect_date','results','lat','lon'], \n",
    "                              keep='last',\n",
    "                              inplace=True)\n",
    "\n",
    "print(f'Number of records after cleaning:  {len(restaurant_df)}')\n",
    "\n",
    "restaurant_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c367e43-3833-4948-8002-7ce4f8e76639",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0909fc12-e086-44c2-a7df-c251e9c35bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5654fe-cd65-447a-84dc-acdb41cfea7c",
   "metadata": {},
   "source": [
    "## Clean Business License Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2225266d-51b6-4cbe-9bfa-fffe10f64dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "business_info = pd.read_csv('data/original/all_licensed_businesses.csv', parse_dates=['PAYMENT DATE','APPLICATION REQUIREMENTS COMPLETE','APPLICATION CREATED DATE','LICENSE TERM START DATE','LICENSE TERM EXPIRATION DATE','LICENSE APPROVED FOR ISSUANCE','DATE ISSUED'])\n",
    "# Note:  APPLICATION CREATED DATE has NaT values as warned below\n",
    "\n",
    "print(f'Original number of records: {len(business_info)}')\n",
    "\n",
    "business_info.drop(['ID', 'LICENSE STATUS', 'ACCOUNT NUMBER', ], axis=1, inplace=True)\n",
    "business_info['ZIP CODE'] = pd.to_numeric(business_info['ZIP CODE'], errors='coerce')\n",
    "business_info.dropna(subset='ZIP CODE', inplace=True)\n",
    "business_info = business_info[business_info['CITY'] == 'CHICAGO']\n",
    "business_info = business_info[~business_info['APPLICATION TYPE'].isin(['C_LOC', 'C_SBA', 'C_EXPA', 'C_CAPA'])]\n",
    "\n",
    "# keep only pertinent columns\n",
    "business_info = business_info[['DOING BUSINESS AS NAME','LICENSE ID', 'ADDRESS', 'WARD', 'PRECINCT', 'POLICE DISTRICT', 'LICENSE CODE', 'LICENSE DESCRIPTION', 'LICENSE NUMBER','BUSINESS ACTIVITY ID', 'BUSINESS ACTIVITY', \n",
    "               'APPLICATION TYPE','APPLICATION REQUIREMENTS COMPLETE', 'CONDITIONAL APPROVAL', 'LICENSE TERM START DATE', \n",
    "               'LICENSE TERM EXPIRATION DATE', 'LICENSE APPROVED FOR ISSUANCE', 'DATE ISSUED']]\n",
    "\n",
    "business_info.columns = ['aka_name', 'license_id', 'address', 'ward', 'precint',\n",
    "                           'police_district', 'license_code',\n",
    "                           'license_description', 'license_num', 'bus_activity_id',\n",
    "                           'bus_activity', 'application_type',\n",
    "                           'app_complete', 'conditional_approval',\n",
    "                           'license_start_date', 'license_end_date',\n",
    "                           'license_issued_date', 'date_issued']\n",
    "\n",
    "# fixes most missing start date issues\n",
    "business_info = business_info.assign(approx_start_date = lambda x: date_select(x))\n",
    "\n",
    "# fixes about 2500 start date issues - date_issued is not as good of a metric - often off by 1 year\n",
    "temp = business_info[business_info['approx_start_date'].isna()]  \n",
    "temp['approx_start_date'] = temp['date_issued']\n",
    "# remove temp records from business_info and add updated records\n",
    "business_info.drop(labels=temp.index, axis=0, inplace=True)\n",
    "business_info = pd.concat([business_info, temp], axis=0)\n",
    "\n",
    "\n",
    "business_info['year'] = business_info['approx_start_date'].dt.strftime('%Y')  \n",
    "\n",
    "# strip white space from object types\n",
    "columns = business_info.select_dtypes(['object']).columns\n",
    "business_info[columns] = business_info[columns].apply(lambda x: x.str.strip())\n",
    "\n",
    "# create unique license num, year combo\n",
    "business_info.drop_duplicates(subset=['aka_name', 'address', 'ward', 'precint',\n",
    "       'police_district', 'license_code', 'license_description', 'license_num',\n",
    "       'bus_activity_id', 'bus_activity','conditional_approval','year'], keep='last', inplace=True)\n",
    "\n",
    "temp = business_info[business_info.duplicated(subset=['license_num','year'], keep=False).sort_values(ascending=True)].sort_values(by='aka_name', ascending=True)\n",
    "\n",
    "# many \n",
    "idx = {}\n",
    "description = {}\n",
    "for index, row in temp.iterrows():\n",
    "    if isinstance(row['bus_activity'], str):\n",
    "        store0 = row['bus_activity_id']\n",
    "        store1 = row['bus_activity']\n",
    "        idx[row['license_num']] = store0\n",
    "        description[row['license_num']] = store1\n",
    "\n",
    "temp['bus_activity_id'] = temp['license_num'].map(idx)\n",
    "temp['bus_activity'] = temp['license_num'].map(description)\n",
    "\n",
    "business_info.drop(labels=temp.index, axis=0, inplace=True)\n",
    "business_info = pd.concat([business_info, temp], axis=0)\n",
    "\n",
    "business_info.drop_duplicates(subset=['aka_name', 'address', 'ward', 'precint',\n",
    "       'police_district', 'license_code', 'license_description', 'license_num',\n",
    "       'bus_activity_id', 'bus_activity','conditional_approval','year'], keep='last', inplace=True)\n",
    "\n",
    "# remove all remaining missing date data - removes < 100 records\n",
    "business_info.dropna(subset='approx_start_date', inplace=True)\n",
    "\n",
    "# remove anything without an aka_name\n",
    "business_info.dropna(subset=['aka_name'], axis=0, inplace=True)\n",
    "\n",
    "business_info['year'] = business_info['year'].astype('int')\n",
    "\n",
    "print(f'Number of records after cleaning:  {len(business_info)}')\n",
    "\n",
    "business_info = business_info[['aka_name', 'license_id', 'address', 'ward', 'precint',\n",
    "       'police_district', 'license_code', 'license_description', 'license_num',\n",
    "       'bus_activity_id', 'bus_activity', 'application_type',\n",
    "       'conditional_approval', 'approx_start_date', 'year']]\n",
    "\n",
    " # 48% of the business_activity and business_activity_id are NaN\n",
    "business_info['bus_activity_id'].fillna('Unknown', inplace=True)\n",
    "business_info['bus_activity'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Calculate business age\n",
    "min_max_year = business_info[['aka_name','address','year']].groupby(['aka_name','address']).agg({'year':['min','max']})\n",
    "min_max_year.reset_index(inplace=True)\n",
    "df = pd.DataFrame(min_max_year.to_records())\n",
    "df.drop(labels=['index'], axis=1, inplace=True)\n",
    "df.columns=['aka_name', 'address', 'year_min', 'year_max']\n",
    "\n",
    "# Combine summarized results to with original dataframe\n",
    "business_info = pd.merge(business_info, df, left_on=['aka_name', 'address'], right_on=['aka_name', 'address'], how='left')\n",
    "business_info['bus_age'] = business_info['approx_start_date'].dt.year - business_info['year_min']\n",
    "business_info.head()\n",
    "\n",
    "business_info.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d2e221-897b-451d-a4a3-a6d8f3492c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "business_info.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed7781a-4302-4018-9124-1a8e3d188031",
   "metadata": {},
   "outputs": [],
   "source": [
    "business_info.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8816ec-0598-4a01-88de-a1cde668def8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Merge Both Datasets Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5634b0-e2d1-48f3-b3a1-a8ff94a24561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that there are no duplicates in the right merge table based on the keys - this will cause duplication\n",
    "business_info_nodupes = business_info.drop_duplicates(subset=['license_num', 'year'], keep='first')\n",
    "# business_info_nodupes.groupby(['license_num','year']).count()['aka_name'].sort_values(ascending=False)\n",
    "# # shows that there are only single records for each license number and year combination.\n",
    "\n",
    "# Merge shows it still has 150k rows but some are NaN values\n",
    "restaurant_df = pd.merge(restaurant_df, business_info_nodupes, left_on=['license_num','year'], right_on=['license_num','year'], how='left')\n",
    "# restaurant_df.shape\n",
    "\n",
    "# the first merge was successful for 16,000 rows but 79,000 rows were still mostly Nan\n",
    "temp = restaurant_df[restaurant_df.isna().sum(axis=1) > 8][['inspect_id', 'aka_name_x', 'license_num', 'facility_type', 'risk',\n",
    "       'address_x', 'city', 'state', 'zipcode', 'inspect_date', 'inspect_type',\n",
    "       'results', 'violations', 'lat', 'lon', 'violations_list',\n",
    "       'violation_count', 'violation_number', 'vl_must_comply_list',\n",
    "       'vl_must_comply_count', 'vl_instructed_comply_list', 'vl_instructed_comply_count',\n",
    "       'vl_not_cited_list', 'vl_citation_count', 'year', 'month']]\n",
    "\n",
    "temp.reset_index(inplace=True)\n",
    "\n",
    "# Strategey to combine more records is to reduce the specificity of the merge \n",
    "# First isolate the NaN values (> 8 NaN values in a row) \n",
    "# Merge to this limted dataframe, first on license number alone, then drop those indexes from the original dataframe and add the updated data to the original\n",
    "# Next isolate the NaN values, and merge on name and address which will be less accurate then drop index from original dateaframe and add updated data to the original\n",
    "# Important note:  make sure that right table of the merge has not duplcates for the merging keys - this prevents duplication of records in the original dataframe\n",
    "\n",
    "# # this verifies that the right table does not have duplicates\n",
    "business_info_nodupes2 = business_info_nodupes.drop_duplicates(subset=['license_num'], keep='first')\n",
    "# business_info_nodupes2.groupby(['license_num']).count()['aka_name'].sort_values(ascending=False)\n",
    "\n",
    "# the second merge was successful for 77,000 rows but 1,500 rows were still mostly Nan\n",
    "temp2 = pd.merge(temp, business_info_nodupes2, left_on=['license_num'], right_on=['license_num'], how='left')\n",
    "temp2.set_index('index', inplace=True)\n",
    "\n",
    "temp2.drop(labels='year_y', axis=1, inplace=True)\n",
    "temp2.rename(columns={'year_x':'year', 'aka_name':'aka_name_y', 'address':'address_y'}, inplace=True)\n",
    "\n",
    "# remove temp records from restaurant_df and add updated records\n",
    "restaurant_df.drop(labels=temp2.index, axis=0, inplace=True)\n",
    "restaurant_df = pd.concat([restaurant_df, temp2], axis=0)\n",
    "\n",
    "temp3 = temp2[temp2.isna().sum(axis=1) > 8]\n",
    "# remove the final mismatches since there should be a match on license number\n",
    "restaurant_df.drop(labels=temp3.index, axis=0, inplace=True)\n",
    "\n",
    "# drop non-name records ~700 records\n",
    "restaurant_df.dropna(subset='aka_name_x', inplace=True, axis=0)\n",
    "\n",
    "# create a new license number for every name/address combination\n",
    "temp = restaurant_df.groupby(['aka_name_x', 'address_x']).min()[['license_num']]\n",
    "name_address = temp.index\n",
    "new_license_number = {(i,j): k for k,(i,j) in enumerate(name_address)}\n",
    "\n",
    "# add license alias to dataframe\n",
    "restaurant_df['license_alias'] = restaurant_df.apply(lambda x: new_license_number[x.aka_name_x,x.address_x], axis=1)\n",
    "\n",
    "# add number of chains that exist\n",
    "temp = restaurant_df.groupby('aka_name_x').count()\n",
    "names = temp.index\n",
    "\n",
    "number_of_chains ={}\n",
    "for name in names:\n",
    "    num = restaurant_df[restaurant_df['aka_name_x']== name]['license_alias'].nunique()  \n",
    "    number_of_chains[name] = num\n",
    "    \n",
    "restaurant_df['number_of_chains'] = restaurant_df.apply(lambda x: number_of_chains[x.aka_name_x], axis=1)\n",
    "\n",
    "# not a fast calculation\n",
    "Audio(sound_file, autoplay=True) \n",
    "\n",
    "restaurant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463f1b8c-c21b-4a36-8314-8941c3ebff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65450a8b-5d47-41aa-8d1f-b35cf17bb324",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5817a1-6b0a-4ad2-8029-633d48682283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note:  approximate_start_date should probably not be used; there is potential that the other categoricals could be wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09797c69-cfb9-4ca4-a96f-66c1fef1c865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export to csv\n",
    "# restaurant_df.to_csv('./data/manipulated/combined_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
